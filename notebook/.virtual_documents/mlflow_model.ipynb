# !pip install mlflow


# !pip install xgboost


import pandas as pd
import mlflow
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import KFold
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \
                            precision_score, recall_score, f1_score, roc_auc_score, \
                            roc_curve,confusion_matrix


data = pd.read_csv('process.csv', index_col=0)
data.head()


# Independent and dependent data
x = data[data.columns.difference(['class'])]
y = data['class']


# Scaler data
scaler =  StandardScaler()
Xscale  = scaler.fit_transform(x)
Xscale


# train test split
X_train, X_test, y_train, y_test = train_test_split(Xscale, y, test_size = 0.20, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape


# local notebook mlflow 
# mlflow.set_tracking_uri("sqlite:///mlflow.db")
# mlflow.set_experiment("xgboost-ml")

# mlflow.client
# from mlflow.tracking import MlflowClient
# client = MlflowClient("sqlite:///mlflow.db")


# mlflow ui setup
import mlflow

mlflow.set_tracking_uri("http://127.0.0.1:5000")
print(f"tracking URI: '{mlflow.get_tracking_uri()}'")


# first run
mlflow.set_experiment("xgboost-ml")
xgboost_params = {
    'max_depth':range(3,10,2),
    'min_child_weight':range(1,6,2)
}
kf = KFold(n_splits=30)
           
with mlflow.start_run():
    mlflow.set_tag("model","XGBClassifier")
    mlflow.log_param("xgboost_params",xgboost_params)

    randomcv_models = XGBClassifier()

    random = RandomizedSearchCV(estimator=randomcv_models,
                                        param_distributions=xgboost_params,
                                       n_iter=100,
                                       cv=kf,
                                       verbose=2, 
                                       n_jobs=-1)
    random.fit(X_train, y_train)
    print(random.best_params_)
    
    y_pred = random.predict(X_test)

    mlflow.sklearn.log_model(random, artifact_path="models")


# first search
mlflow.search_experiments()





#second run
mlflow.set_experiment("xgboost-ml-2")

xgboost_params = {
    'max_depth':range(3,10,2),
    'min_child_weight':range(1,6,2)
}
kf = KFold(n_splits=30)
           
with mlflow.start_run():
    mlflow.set_tag("model","XGBClassifier")
    mlflow.log_param("xgboost_params",xgboost_params)

    randomcv_models = XGBClassifier()

    random = RandomizedSearchCV(estimator=randomcv_models,
                                        param_distributions=xgboost_params,
                                       n_iter=100,
                                       cv=kf,
                                       verbose=2, 
                                       n_jobs=-1)
    random.fit(X_train, y_train)
    print(random.best_params_)
    
    y_pred = random.predict(X_test)

    mlflow.sklearn.log_model(random, artifact_path="models")
    print(f"default artifacts URI: '{mlflow.get_artifact_uri()}'")


# Second search
mlflow.search_experiments()


#third run
mlflow.set_experiment("xgboost-ml-3")
xgboost_params = {
    'max_depth':range(3,10,2),
    'min_child_weight':range(1,6,2)
}
kf = KFold(n_splits=30)

with mlflow.start_run():
    mlflow.set_tag("model","XGBClassifier")
    mlflow.log_param("xgboost_params",xgboost_params)

    randomcv_models = XGBClassifier()

    random = RandomizedSearchCV(estimator=randomcv_models,
                                        param_distributions=xgboost_params,
                                       n_iter=100,
                                       cv=kf,
                                       verbose=2, 
                                       n_jobs=-1)
    random.fit(X_train, y_train)
    print(random.best_params_)
    
    y_pred = random.predict(X_test)

    mlflow.sklearn.log_model(random, artifact_path="models")
    print(f"default artifacts URI: '{mlflow.get_artifact_uri()}'")


# Third search
mlflow.search_experiments()


from mlflow.tracking import MlflowClient

client = MlflowClient()
model_name = "xgboost-ml"

# latest_versions = client.get_latest_versions(model_name)

latest_versions = client.get_experiment_by_name(name=model_name)
for version in latest_versions:
    print(version)
    


# model_name = "xgboost-ml"
# model_version = 3
# new_stage = "Staging"
# client.transition_model_version_stage(
#     name=model_name,
#     version=model_version,
#     stage=new_stage,
#     archive_existing_versions=False
# )


def test_model(name, stage, X_test, y_test):
    model = mlflow.pyfunc.load_model(f"models:/{name}/{stage}")
    y_pred = model.predict(X_test)
    return {"rmse": mean_squared_error(y_test, y_pred, squared=False)}


# interacting model registry


from mlflow.tracking import MlflowClient

client = MlflowClient("http://127.0.0.1:5000")

run_id=client.get_experiment(experiment_id='3')

print(run_id)


id = client.create_registered_model(name='xgboost-ml-3')
print(id)


# model-version
client = MlflowClient()
result = client.create_model_version(
    name='xgboost-ml-3')


# final aws ec2 main script file


# Hypertunning Random_search 
xgboost_params = {
    'max_depth':range(3,10,2),
    'min_child_weight':range(1,6,2)
}

kf = KFold(n_splits=30)

model_param = {}

randomcv_models = XGBClassifier()

random = RandomizedSearchCV(estimator=randomcv_models,
                                    param_distributions=xgboost_params,
                                   n_iter=100,
                                   cv=kf,
                                   verbose=2, 
                                   n_jobs=-1)
random.fit(Xscale, y)
model_param = random.best_params_
print(model_param)



params = {'min_child_weight': 3, 'max_depth': 5}

best_model = XGBClassifier(**params)
best_model = best_model.fit(X_train,y_train)
y_pred = best_model.predict(X_test)
score = accuracy_score(y_test,y_pred)
cr = classification_report(y_test,y_pred)

print("FINAL MODEL 'XGBoost'")
print ("Accuracy Score value: {:.4f}".format(score))
print (cr)



